---
title: "error_analysis"
author: "Sara Orofino"
date: "12/2/2019"
output: html_document
---

#{.tabset}

##Setup

```{r setup, include=FALSE, warning=FALSE, message=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#Packages
library(tidyverse)
library(here)

#Data
err_rep5c <- read_csv(file=file.path(here(),"/Results/error/error_constant_rep5.csv"))
err_rep5u <- read_csv(file=file.path(here(),"/Results/error/error_updating_rep5.csv"))
err_rep10c <- read_csv(file=file.path(here(),"/Results/error/error_constant_rep10.csv"))
err_rep10u <- read_csv(file=file.path(here(),"/Results/error/error_updating_rep10.csv"))

```


##Decision Calculation
 - Filter negative climate change 
 - Filter for assessment years ONLY
 - Group simulations by error percentage
 - Count the number of times the model chose a ratio that led the manager to make the wrong decision

#Rep5 - Updating
Do some basic data wrangling for 5 year intervals where Fmsy updating with climate change:
  - Look at all negative climate change scenarios
  - Look at ONLY assessments where a decision was actually made (filter out times when the fishery was closed)
  - Group by error percentage 
```{r wrangle-5u-basic}
#Assessment years:
assess_5 <- seq(5,100,5)

#Find the proportion of wrong decisions excluding assessments where the fishery was closed 
rep5u_no <- err_rep5u %>%
  filter(r_s <= 0) %>% 
  filter(year == 1 | year %in% assess_5) %>% 
  filter(decision_made == "yes") %>% 
  group_by(error, correct_decision) %>% 
  tally() %>% 
  rename("count_5u" = n) %>% 
  spread(key = "correct_decision", value = "count_5u") %>%
  mutate(total_decisions_made = sum(no + yes)) %>% 
  mutate(prop_5u = no/total_decisions_made)

#Now I want to transform the error into factors
rep5u_no$error <- as.factor(rep5u_no$error)

```


Now I want to see how many "fails" were included in each error category
```{r 5u-fails}

#Find the proportion of yes, no, and fail for each error category
rep5u_fail <- err_rep5u %>% 
  filter(r_s <= 0) %>% 
  filter(year == 1 | year %in% assess_5) %>% 
  group_by(error, correct_decision) %>% 
  tally() %>% 
  rename("count_5u" = n) %>% 
  spread(key = "correct_decision", value = "count_5u")


```



#Rep10 - Updating
Data wrangling for 10 year intervals where Fmsy is updating with climate change:
```{r wrangle-10u-basic}

#Assessment years:
assess_10 <- seq(10,100,10)

#Find the proportion of wrong decisions excluding assessments where the fishery was closed 
rep10u <- err_rep10u %>%
  filter(r_s <= 0) %>% 
  filter(year == 1 | year %in% assess_10) %>% 
  filter(decision_made == "yes") %>% 
  group_by(error, correct_decision) %>% 
  tally() %>% 
  rename("count_10u" = n) %>% 
  spread(key = "correct_decision", value = "count_10u")

#There are a few scenarios where no wrong decisions are made - change these values from NA to zero
#note you need to do this before calculating any other values (ie total decisions or proportions)
rep10u$no[is.na(rep10u$no)] <- 0

rep10u_no <- rep10u %>% 
  mutate(total_decisions_made = sum(no + yes)) %>% 
  mutate(prop_10u = no/total_decisions_made)

#Now I want to transform the continuous variables (r_s and error) into factors
rep10u_fail$r_s <- as.factor(rep10u_fail$r_s)
rep10u_fail$error <- as.factor(rep10u_fail$error)


```

Now I want to see how many "fails" were included in each error category
```{r 10u-fails}

#Find the proportion of yes, no, and fail for each error category
rep10u_fail <- err_rep10u %>% 
  filter(r_s <= 0) %>% 
  filter(year == 1 | year %in% assess_10) %>% 
  group_by(error, correct_decision) %>% 
  tally() %>% 
  rename("count_10u" = n) %>% 
  spread(key = "correct_decision", value = "count_10u")

##Alright this is also giving me an NA category 

#let's investigate this a bit - the NA values for b and c are from experiment 815
b_na <- err_rep5u %>% 
  filter(id == 815)
#Looks like things get weird with the positive climate influence - that the catch is actually larger than biomass because fishing mortality is greater than one...

#Let's see where the ratio category is NA
ratio_na <- err_rep5u %>% 
  filter(is.na(ratio_err_cat))
#Damn - its drawing negative f_ratio_err's under both 0.3 and 0.5 error estimates....

```


##Visualizations

Experiment with a few ways of visualizing this data

#Rep5

First try proportion of failures on the y-axis with error categories on the x-axis for updating Fmsy
```{r rep5-viz1}

fail5 <- ggplot(rep5u, aes(x = error, y= prop_5u)) +
  geom_jitter(aes(size = r_s, color = r0_cat), alpha = 0.8, width = 0.25)

fail5


```

#Rep10

First try proportion of failures on the y-axis with error categories on the x-axis for updating Fmsy
```{r rep10-viz1}

fail10 <- ggplot(rep10u_fail, aes(x = error, y= prop_10u)) +
  geom_jitter(aes(size = r_s, color = r0_cat), alpha = 0.8, width = 0.25)

fail10


```